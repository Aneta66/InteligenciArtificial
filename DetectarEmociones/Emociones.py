# Entrenamiento del modelo de reconocimiento de emociones
# usando LBPH (Local Binary Patterns Histogram)

import cv2 as cv
import numpy as np
import os
import time

# === RUTA DE TU DATASET ===
dataSet = 'C:/Users/anais/OneDrive/Escritorio/TareaIA/InteligenciArtificial/Emociones'
# En Ubuntu ser√≠a algo como:
# dataSet = '/home/usuario/Emociones'

# === INICIO DEL ENTRENAMIENTO ===
inicio = time.time()
emociones = os.listdir(dataSet)
print("üìÅ Carpetas encontradas:", emociones)

labels = []
facesData = []
label = 0
contador = 0
total = sum(len(os.listdir(os.path.join(dataSet, f))) for f in emociones)

# === LECTURA DE IM√ÅGENES ===
for emo in emociones:
    emoPath = os.path.join(dataSet, emo)
    print(f"\n‚û° Procesando '{emo}' ({len(os.listdir(emoPath))} im√°genes) Label={label}")

    for faceName in os.listdir(emoPath):
        ruta = os.path.join(emoPath, faceName)
        img = cv.imread(ruta, 0)
        if img is None:
            print(f"‚ö†Ô∏è No se pudo leer: {ruta}")
            continue
        img = cv.resize(img, (100,100))
        img = cv.equalizeHist(img)  # mejora contraste y uniformiza luz
        facesData.append(img)
        labels.append(label)
        contador += 1
        if contador % 200 == 0:
            print(f"  Procesadas {contador}/{total} im√°genes...")

    label += 1

print(f"\n‚úÖ Total de im√°genes procesadas: {contador}")
print("üïí Tiempo de carga:", round(time.time() - inicio, 2), "segundos")

# === ENTRENAMIENTO LBPH ===
print("\nüöÄ Iniciando entrenamiento...")
t0 = time.time()
faceRecognizer = cv.face.LBPHFaceRecognizer_create(radius=1, neighbors=8, grid_x=8, grid_y=8)
faceRecognizer.train(facesData, np.array(labels))
t1 = time.time()

print("‚úÖ Entrenamiento completado en", round(t1 - t0, 2), "segundos.")
faceRecognizer.write('Emociones.yml')
print("üíæ Modelo guardado como Emociones.yml")
